{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./../output/only_pieces/'):\n",
    "    os.mkdir('./../output/only_pieces/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   fen_to_piece = {\n",
    "            'K': 'w_King', 'Q': 'w_Queen', 'R': 'w_Rook', 'B': 'w_Bishop', 'N': 'w_Knight', 'P': 'w_Pawn',\n",
    "            'k': 'b_King', 'q': 'b_Queen', 'r': 'b_Rook', 'b': 'b_Bishop', 'n': 'b_Knight', 'p': 'b_Pawn'\n",
    "        }\n",
    "'''\n",
    "if not os.path.exists(f'./../output/only_pieces'):\n",
    "        os.mkdir(f'./../output/only_pieces')\n",
    "\n",
    "classes = [\"w_Pawn\", \"w_Knight\", \"w_Bishop\", \"w_Rook\", \"w_Queen\", \"w_King\",\n",
    "                   \"b_Pawn\", \"b_Knight\", \"b_Bishop\", \"b_Rook\", \"b_Queen\", \"b_King\"]\n",
    "for c in classes:\n",
    "    if not os.path.exists(f'./../output/only_pieces/{c}'):\n",
    "        os.mkdir(f'./../output/only_pieces/{c}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "to_be_processed = glob.glob('./../output/training_pieces/**')\n",
    "coor_content_matrix = []\n",
    "for in_process in to_be_processed[1::2]:\n",
    "    if not os.path.isfile(in_process):\n",
    "        continue\n",
    "        \n",
    "    if in_process.lower().endswith(\".png\"):\n",
    "        continue\n",
    "\n",
    "    #find the base name and open related txt file\n",
    "    base_name = os.path.basename(in_process)\n",
    "    name_parts = os.path.splitext(base_name)[0].split('.txt')\n",
    "\n",
    "    # Open the corresponding text file\n",
    "    if os.path.isfile(in_process):\n",
    "        with open(in_process, 'r') as txt_file:\n",
    "            content = txt_file.read()\n",
    "    else:\n",
    "        print(f\"Text file not found for {base_name}\")\n",
    "\n",
    "    path_file_png_origine = os.path.join('./../output/training_pieces/', f'{name_parts[0]}.png')\n",
    "    path_file_png_destinazione = os.path.join(f'./../output/only_pieces/{content}/', f'{name_parts[0]}.png')\n",
    "    \n",
    "    shutil.copy(path_file_png_origine, path_file_png_destinazione)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_Pawn: 68'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_Knight: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_Bishop: 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_Rook: 19'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_Queen: 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe w_King: 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_Pawn: 70'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_Knight: 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_Bishop: 15'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_Rook: 19'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_Queen: 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Numero di sample della classe b_King: 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classes = [\"w_Pawn\", \"w_Knight\", \"w_Bishop\", \"w_Rook\", \"w_Queen\", \"w_King\",\n",
    "                   \"b_Pawn\", \"b_Knight\", \"b_Bishop\", \"b_Rook\", \"b_Queen\", \"b_King\"]\n",
    "for c in classes:\n",
    "    \n",
    "    display(\"Numero di sample della classe \"+ str(c)+ \": \"+ str(len(os.listdir(f'./../output/only_pieces/{c}'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lunghezza train data: 192'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Lunghezza validation data: 42'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Lunghezza test data: 41'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = './../output/only_pieces/'\n",
    "class_names = [\"w_Pawn\", \"w_Knight\", \"w_Bishop\", \"w_Rook\", \"w_Queen\", \"w_King\",\n",
    "                   \"b_Pawn\", \"b_Knight\", \"b_Bishop\", \"b_Rook\", \"b_Queen\", \"b_King\"]\n",
    "data = []\n",
    "labels = []\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for img_file in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        data.append(img_path)\n",
    "        labels.append(class_name)\n",
    "\n",
    "data, labels = shuffle(data, labels, random_state=42)\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "test_data, validation_data, test_labels, validation_labels = train_test_split(temp_data, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "\n",
    "display(\"Lunghezza train data: \"+ str(len(train_data)))\n",
    "display(\"Lunghezza validation data: \" +str(len(validation_data)))\n",
    "display(\"Lunghezza test data: \" + str(len(test_data)))\n",
    "#display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessPicesDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Carica l'immagine da file\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Applica le trasformazioni se specificate\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le trasformazioni per il tuo dataset (es. resizing, normalizzazione, ecc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100,200)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ChessPicesDataset(train_data, train_labels, transform=transform)\n",
    "validation_ds = ChessPicesDataset(validation_data, validation_labels, transform=transform)\n",
    "test_ds = ChessPicesDataset(test_data, test_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\feder\\anaconda3\\envs\\LabCv2\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\feder\\anaconda3\\envs\\LabCv2\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet18 model\n",
    "resnet_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer for the number of classes in your dataset\n",
    "num_classes = len(set(train_ds.labels))\n",
    "\n",
    "#print(len(img), len(set(lable)))\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the specified device\n",
    "resnet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 1.4326143264770508, Validation Loss: 6.417305946350098\n",
      "Epoch 2/10, Training Loss: 1.611130952835083, Validation Loss: 7.438599586486816\n",
      "Epoch 3/10, Training Loss: 0.35469529032707214, Validation Loss: 1.2338249683380127\n",
      "Epoch 4/10, Training Loss: 0.19556979835033417, Validation Loss: 1.653531551361084\n",
      "Epoch 5/10, Training Loss: 0.1379767209291458, Validation Loss: 1.310896873474121\n",
      "Epoch 6/10, Training Loss: 0.00866552721709013, Validation Loss: 1.390994668006897\n",
      "Epoch 7/10, Training Loss: 0.05487512797117233, Validation Loss: 1.1635704040527344\n",
      "Epoch 8/10, Training Loss: 0.021055564284324646, Validation Loss: 2.0351662635803223\n",
      "Epoch 9/10, Training Loss: 0.006859513930976391, Validation Loss: 1.1216256618499756\n",
      "Epoch 10/10, Training Loss: 0.061165887862443924, Validation Loss: 1.315464973449707\n",
      "Test Accuracy: 70.73%\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "num_epochs = 10\n",
    "\n",
    "# Liste per salvare i valori di loss\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, torch.tensor([class_names.index(label) for label in labels]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validate the model\n",
    "    resnet_model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            outputs = resnet_model(inputs)\n",
    "            valid_loss += criterion(outputs, torch.tensor([class_names.index(label) for label in labels]))\n",
    "\n",
    "    # Calcola la media della loss sul set di validazione\n",
    "    valid_loss /= len(validation_dataloader)\n",
    "\n",
    "    # Aggiorna le liste di loss\n",
    "    train_losses.append(loss.item())\n",
    "    validation_losses.append(valid_loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {valid_loss.item()}')\n",
    "    \n",
    "\n",
    "resnet_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = resnet_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == torch.tensor([class_names.index(label) for label in labels])).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Save the fine-tuned model if needed\n",
    "torch.save(resnet_model.state_dict(), 'fine_tuned_resnet18.pth')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LabCv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
