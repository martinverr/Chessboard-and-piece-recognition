{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occupancy classifier\n",
    "CNN to classify given an input img square if occupied or not by a piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare and Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into folders according to their class (empty - no_empty), based on the labels written in the corresponding text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty: 493 (64.2%)\n",
      "no_empty: 275 (35.8%)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./../scratch-cnn/data/'):\n",
    "    os.mkdir('./../scratch-cnn/data/')\n",
    "\n",
    "if not os.path.exists('./../scratch-cnn/data/empty/'):\n",
    "    os.mkdir('./../scratch-cnn/data/empty/')\n",
    "\n",
    "if not os.path.exists('./../scratch-cnn/data/no_empty/'):\n",
    "    os.mkdir('./../scratch-cnn/data/no_empty/')\n",
    "\n",
    "for filename in os.listdir('./../output/training_squares/'):\n",
    "    if filename.endswith('.png'):\n",
    "       \n",
    "        txt_filename = os.path.join('./../output/training_squares/', f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "\n",
    "        # Verificare se il file di testo contiene \"empty\"\n",
    "        with open(txt_filename, 'r') as file:\n",
    "            contenuto = file.read()\n",
    "            if 'empty' in contenuto:\n",
    "                # Spostare l'immagine nella cartella empty\n",
    "                shutil.copy(os.path.join('./../output/training_squares/', filename), os.path.join('./../scratch-cnn/data/empty/', filename))\n",
    "            else:\n",
    "                # Spostare l'immagine nella cartella non_empty\n",
    "                shutil.copy(os.path.join('./../output/training_squares/', filename), os.path.join('./../scratch-cnn/data/no_empty/', filename))\n",
    "\n",
    "\n",
    "num_empty = len(os.listdir('./../scratch-cnn/data/empty/'))\n",
    "num_no_empty = len(os.listdir('./../scratch-cnn/data/no_empty/'))\n",
    "print(f\"empty: {num_empty} ({num_empty/(num_empty+num_no_empty):.1%})\")\n",
    "print(f\"no_empty: {num_no_empty} ({num_no_empty/(num_empty+num_no_empty):.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create \"data\", list of the img paths of the dataset.\n",
    "\n",
    "Create \"labels\", list of the corresponding target class label.\n",
    "\n",
    "Shuffle and split into train, test, validation sets (70-15-15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 537\n",
      "validation: 116\n",
      "test: 115\n",
      "test data files:\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './../scratch-cnn/data/'\n",
    "class_names = ['empty', 'no_empty']\n",
    "data = []\n",
    "labels = []\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for img_file in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        data.append(img_path)\n",
    "        labels.append(class_name)\n",
    "\n",
    "data, labels = shuffle(data, labels, random_state=42)\n",
    "\n",
    "# Split the data into training and temporary sets\n",
    "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "test_data, validation_data, test_labels, validation_labels = train_test_split(temp_data, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "\n",
    "print(f\"train: {len(train_data)}\")\n",
    "print(f\"validation: {len(validation_data)}\")\n",
    "print(f\"test: {len(test_data)}\")\n",
    "print(\"test data files:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset for torch (Dataset and DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Carica l'immagine da file\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Applica le trasformazioni se specificate\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci le trasformazioni per il tuo dataset (es. resizing, normalizzazione, ecc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((80, 80)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomDataset(train_data, train_labels, transform=transform)\n",
    "validation_ds = CustomDataset(validation_data, validation_labels, transform=transform)\n",
    "test_ds = CustomDataset(test_data, test_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea i dataloader\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_ds, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "\n",
    "- CNN_80x80_2Conv_2Pool_2FC: input 80x80 x3channels; 2 conv, 2 pool, 2 fully connected; output 2 classes\n",
    "- other to add and try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_80x80_2Conv_2Pool_2FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_80x80_2Conv_2Pool_2FC, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 20 * 20, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 2)  # Two output classes: empty and no_empty\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        probabilities = F.softmax(x, dim=1)\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Training Loss: 0.6196062564849854, Validation Loss: 0.6520897150039673\n",
      "Epoch 2/150, Training Loss: 0.6822412610054016, Validation Loss: 0.6330687999725342\n",
      "Epoch 3/150, Training Loss: 0.5974573493003845, Validation Loss: 0.6250340938568115\n",
      "Epoch 4/150, Training Loss: 0.5014282464981079, Validation Loss: 0.5621515512466431\n",
      "Epoch 5/150, Training Loss: 0.6099306344985962, Validation Loss: 0.5611372590065002\n",
      "Epoch 6/150, Training Loss: 0.49157091975212097, Validation Loss: 0.48792803287506104\n",
      "Epoch 7/150, Training Loss: 0.4672378599643707, Validation Loss: 0.44659316539764404\n",
      "Epoch 8/150, Training Loss: 0.47116631269454956, Validation Loss: 0.4615148901939392\n",
      "Epoch 9/150, Training Loss: 0.49912482500076294, Validation Loss: 0.43348243832588196\n",
      "Epoch 10/150, Training Loss: 0.39376208186149597, Validation Loss: 0.4612685441970825\n",
      "Epoch 11/150, Training Loss: 0.43906664848327637, Validation Loss: 0.3930802345275879\n",
      "Epoch 12/150, Training Loss: 0.38520023226737976, Validation Loss: 0.40273308753967285\n",
      "Epoch 13/150, Training Loss: 0.36005592346191406, Validation Loss: 0.36628520488739014\n",
      "Epoch 14/150, Training Loss: 0.4680132567882538, Validation Loss: 0.4097945988178253\n",
      "Epoch 15/150, Training Loss: 0.33741244673728943, Validation Loss: 0.361190527677536\n",
      "Epoch 16/150, Training Loss: 0.48279520869255066, Validation Loss: 0.368868350982666\n",
      "Epoch 17/150, Training Loss: 0.32293185591697693, Validation Loss: 0.3988097310066223\n",
      "Epoch 18/150, Training Loss: 0.3219958543777466, Validation Loss: 0.4674435555934906\n",
      "Epoch 19/150, Training Loss: 0.3969210386276245, Validation Loss: 0.41228359937667847\n",
      "Epoch 20/150, Training Loss: 0.3514081835746765, Validation Loss: 0.36100029945373535\n",
      "Epoch 21/150, Training Loss: 0.3642949163913727, Validation Loss: 0.3449766933917999\n",
      "Epoch 22/150, Training Loss: 0.3174741566181183, Validation Loss: 0.34274476766586304\n",
      "Epoch 23/150, Training Loss: 0.38066256046295166, Validation Loss: 0.3528788685798645\n",
      "Epoch 24/150, Training Loss: 0.39720916748046875, Validation Loss: 0.3650973439216614\n",
      "Epoch 25/150, Training Loss: 0.3190465569496155, Validation Loss: 0.35399702191352844\n",
      "Epoch 26/150, Training Loss: 0.31798893213272095, Validation Loss: 0.3397449254989624\n",
      "Epoch 27/150, Training Loss: 0.34050968289375305, Validation Loss: 0.36764228343963623\n",
      "Epoch 28/150, Training Loss: 0.3380611836910248, Validation Loss: 0.33539289236068726\n",
      "Epoch 29/150, Training Loss: 0.3139652907848358, Validation Loss: 0.34371405839920044\n",
      "Epoch 30/150, Training Loss: 0.3244245648384094, Validation Loss: 0.5527514219284058\n",
      "Epoch 31/150, Training Loss: 0.31864863634109497, Validation Loss: 0.35069161653518677\n",
      "Epoch 32/150, Training Loss: 0.3399469256401062, Validation Loss: 0.34927892684936523\n",
      "Epoch 33/150, Training Loss: 0.3155154287815094, Validation Loss: 0.37103015184402466\n",
      "Epoch 34/150, Training Loss: 0.31417781114578247, Validation Loss: 0.33281415700912476\n",
      "Epoch 35/150, Training Loss: 0.31867942214012146, Validation Loss: 0.33412569761276245\n",
      "Epoch 36/150, Training Loss: 0.3147946894168854, Validation Loss: 0.3330656886100769\n",
      "Epoch 37/150, Training Loss: 0.31445056200027466, Validation Loss: 0.33147382736206055\n",
      "Epoch 38/150, Training Loss: 0.3145226240158081, Validation Loss: 0.3336559236049652\n",
      "Epoch 39/150, Training Loss: 0.3386978507041931, Validation Loss: 0.3345050513744354\n",
      "Epoch 40/150, Training Loss: 0.313546359539032, Validation Loss: 0.33364036679267883\n",
      "Epoch 41/150, Training Loss: 0.3163882791996002, Validation Loss: 0.33397072553634644\n",
      "Epoch 42/150, Training Loss: 0.31360098719596863, Validation Loss: 0.3362780511379242\n",
      "Epoch 43/150, Training Loss: 0.31356292963027954, Validation Loss: 0.33014610409736633\n",
      "Epoch 44/150, Training Loss: 0.3133544623851776, Validation Loss: 0.33409205079078674\n",
      "Epoch 45/150, Training Loss: 0.3533518612384796, Validation Loss: 0.33076608180999756\n",
      "Epoch 46/150, Training Loss: 0.3136502206325531, Validation Loss: 0.3325219452381134\n",
      "Epoch 47/150, Training Loss: 0.3136141896247864, Validation Loss: 0.3307115435600281\n",
      "Epoch 48/150, Training Loss: 0.3134353756904602, Validation Loss: 0.33262816071510315\n",
      "Epoch 49/150, Training Loss: 0.3135155737400055, Validation Loss: 0.33087605237960815\n",
      "Epoch 50/150, Training Loss: 0.3135162591934204, Validation Loss: 0.3317306637763977\n",
      "Epoch 51/150, Training Loss: 0.3134716749191284, Validation Loss: 0.3305439352989197\n",
      "Epoch 52/150, Training Loss: 0.3133864998817444, Validation Loss: 0.3316429853439331\n",
      "Epoch 53/150, Training Loss: 0.31372418999671936, Validation Loss: 0.33042627573013306\n",
      "Early stopping after 53 epochs without improvement.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\n\\n# Plot dei valori di training loss e validation loss\\nplt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\\nplt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\\nplt.xlabel('Epoch')\\nplt.ylabel('Loss')\\nplt.legend()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inizializza la rete\n",
    "model = CNN_80x80_2Conv_2Pool_2FC()\n",
    "\n",
    "# Definisci la loss function e l'ottimizzatore\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Definisci il numero di epoche per il training\n",
    "num_epochs = 150\n",
    "\n",
    "# Inizializza le variabili per l'early stopping\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_patience = 10  # Sostituisci con il tuo valore desiderato\n",
    "early_stopping_counter = 0\n",
    "\n",
    "# Liste per salvare i valori di loss\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "# Training della rete\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, torch.tensor([class_names.index(label) for label in labels]))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Valutazione sul set di validazione\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0.0\n",
    "        for inputs, labels in validation_dataloader:\n",
    "            outputs = model(inputs)\n",
    "            valid_loss += criterion(outputs, torch.tensor([class_names.index(label) for label in labels]))\n",
    "\n",
    "    # Calcola la media della loss sul set di validazione\n",
    "    valid_loss /= len(validation_dataloader)\n",
    "\n",
    "    # Aggiorna le liste di loss\n",
    "    train_losses.append(loss.item())\n",
    "    validation_losses.append(valid_loss.item())\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {valid_loss.item()}')\n",
    "\n",
    "    # Controlla se la loss sul set di validazione Ã¨ migliorata\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        # Incrementa il contatore di early stopping\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    # Se la loss non migliora per un numero specifico di epoche, interrompi il training\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f'Early stopping after {epoch + 1} epochs without improvement.')\n",
    "        break\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot dei valori di training loss e validation loss\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CNN_80x80_2Conv_2Pool_2FC.pth\n"
     ]
    }
   ],
   "source": [
    "# TODO: both training and save should loop among models when there will be more than one model\n",
    "model_saves_path = './../scratch-cnn/modelsaves/'\n",
    "\n",
    "if not os.path.exists(model_saves_path):\n",
    "    os.mkdir(model_saves_path)\n",
    "\n",
    "# NOTE: forse conviene save(model) invece di model.state_dict perche' intanto non \n",
    "#       abbiamo operazioni particolari, solo fare load()\n",
    "torch.save(model.state_dict(), f\"{model_saves_path}{model._get_name()}.pth\")\n",
    "print(f\"Saved {model._get_name()}.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.52%\n"
     ]
    }
   ],
   "source": [
    "# Test della rete\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == torch.tensor([class_names.index(label) for label in labels])).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.eval()\\ncorrect = 0\\ntotal = 0\\nc = 0\\nwith torch.no_grad():\\n    for inputs, labels in test_dataloader:\\n        outputs = model(inputs)\\n        _, predicted = torch.max(outputs, 1)\\n        total += len(labels)\\n        correct += (predicted == torch.tensor([class_names.index(label) for label in labels])).sum().item()\\n\\n        # Stampa per ogni input corretto o non corretto\\n        for i in range(len(labels)):\\n            prediction_correct = (predicted[i] == class_names.index(labels[i]))\\n            print(f\"Input {c}: {\\'Correct\\' if prediction_correct else \\'Incorrect\\'}\")\\n            c=c+1\\n            print(f\"   Predicted: {class_names[predicted[i]]}, True: {labels[i]}\\n\")\\n\\naccuracy = correct / total\\nprint(f\\'Test Accuracy: {accuracy * 100:.2f}%\\')\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "c = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += len(labels)\n",
    "        correct += (predicted == torch.tensor([class_names.index(label) for label in labels])).sum().item()\n",
    "\n",
    "        # Stampa per ogni input corretto o non corretto\n",
    "        for i in range(len(labels)):\n",
    "            prediction_correct = (predicted[i] == class_names.index(labels[i]))\n",
    "            print(f\"Input {c}: {'Correct' if prediction_correct else 'Incorrect'}\")\n",
    "            c=c+1\n",
    "            print(f\"   Predicted: {class_names[predicted[i]]}, True: {labels[i]}\\n\")\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other\n",
    "Debug, single predict, summary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test_data[146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 80, 80])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 6.7168e-11]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path = './../scratch-cnn/data/no_empty/0026_E8.png'\n",
    "\n",
    "img = Image.open(img_path)\n",
    "\n",
    "img = transform(img)\n",
    "img = img.reshape([1, 3, 80, 80])\n",
    "display(img.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 80, 80]             448\n",
      "              ReLU-2           [-1, 16, 80, 80]               0\n",
      "         MaxPool2d-3           [-1, 16, 40, 40]               0\n",
      "            Conv2d-4           [-1, 32, 40, 40]           4,640\n",
      "              ReLU-5           [-1, 32, 40, 40]               0\n",
      "         MaxPool2d-6           [-1, 32, 20, 20]               0\n",
      "           Flatten-7                [-1, 12800]               0\n",
      "            Linear-8                  [-1, 128]       1,638,528\n",
      "              ReLU-9                  [-1, 128]               0\n",
      "           Linear-10                    [-1, 2]             258\n",
      "================================================================\n",
      "Total params: 1,643,874\n",
      "Trainable params: 1,643,874\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 2.74\n",
      "Params size (MB): 6.27\n",
      "Estimated Total Size (MB): 9.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch.onnx\n",
    "\n",
    "\n",
    "\n",
    "# Mostra una rappresentazione tabulare del modello\n",
    "summary(model, input_size=(3, 80, 80))  # Cambia le dimensioni in base alla tua immagine di input\n",
    "\n",
    "# Salva il modello in formato ONNX\n",
    "dummy_input = torch.randn(1, 3, 80, 80)  # Cambia le dimensioni in base alla tua immagine di input\n",
    "onnx_path = \"simple_cnn.onnx\"\n",
    "torch.onnx.export(model, dummy_input, onnx_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
